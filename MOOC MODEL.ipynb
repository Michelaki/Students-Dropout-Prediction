{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec0e1523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mooc = pd.read_csv('big_student_clear_third_version.csv')\n",
    "\n",
    "mooc = mooc.drop(columns=['Unnamed: 0','gender','incomplete_flag']) # drop columns with no metadata about their content\n",
    "\n",
    "mooc = mooc.rename(columns={\"userid_DI\": \"userid\", \"final_cc_cname_DI\": \"country\",\"LoE_DI\":\"education\",\n",
    "                            \"start_time_DI\":\"start_time\", \"last_event_DI\":\"last_event\" }) # rename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57bfd73",
   "metadata": {},
   "source": [
    "#  Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "324a27d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\B590\\AppData\\Local\\Temp\\ipykernel_8604\\2693734390.py:9: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mooc = mooc.drop(mooc[mooc['certified']==1][mooc['grade']< 0.5].index) # drop the 1 line that someone\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "mooc['last_event'] = pd.to_datetime(mooc['last_event'])   # create a column for the duration of studies\n",
    "mooc['start_time'] = pd.to_datetime(mooc['start_time'])\n",
    "mooc['duration'] = mooc['last_event'] - mooc['start_time']\n",
    "\n",
    "mooc = mooc.drop(mooc[mooc['duration']< '0 days'].index) # drop the 1231 lines with negative duration\n",
    "\n",
    "mooc = mooc.drop(mooc[mooc['certified']==1][mooc['grade']< 0.5].index) # drop the 1 line that someone \n",
    "                                                                       # graduated with grade less than 50 %\n",
    "    \n",
    "# drop the lines where age < 5\n",
    "mooc = mooc.drop(mooc[mooc['age']< 5].index)  # 279 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4640694b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>institute</th>\n",
       "      <th>course_id</th>\n",
       "      <th>year</th>\n",
       "      <th>semester</th>\n",
       "      <th>userid</th>\n",
       "      <th>viewed</th>\n",
       "      <th>explored</th>\n",
       "      <th>certified</th>\n",
       "      <th>country</th>\n",
       "      <th>education</th>\n",
       "      <th>grade</th>\n",
       "      <th>start_time</th>\n",
       "      <th>last_event</th>\n",
       "      <th>nevents</th>\n",
       "      <th>ndays_act</th>\n",
       "      <th>nplay_video</th>\n",
       "      <th>nchapters</th>\n",
       "      <th>nforum_posts</th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HarvardX</td>\n",
       "      <td>PH207x</td>\n",
       "      <td>2012</td>\n",
       "      <td>Fall</td>\n",
       "      <td>MHxPC130313697</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>India</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-07-24</td>\n",
       "      <td>2013-07-27</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>197757</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>368 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HarvardX</td>\n",
       "      <td>PH207x</td>\n",
       "      <td>2012</td>\n",
       "      <td>Fall</td>\n",
       "      <td>MHxPC130237753</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Secondary</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-07-24</td>\n",
       "      <td>2012-12-24</td>\n",
       "      <td>107</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>153 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HarvardX</td>\n",
       "      <td>CS50x</td>\n",
       "      <td>2012</td>\n",
       "      <td>Summer</td>\n",
       "      <td>MHxPC130202970</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-07-24</td>\n",
       "      <td>2013-03-28</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>197757</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>247 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HarvardX</td>\n",
       "      <td>CS50x</td>\n",
       "      <td>2012</td>\n",
       "      <td>Summer</td>\n",
       "      <td>MHxPC130223941</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Other Middle East/Central Asia</td>\n",
       "      <td>Secondary</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-07-24</td>\n",
       "      <td>2013-07-15</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>197757</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>356 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HarvardX</td>\n",
       "      <td>PH207x</td>\n",
       "      <td>2012</td>\n",
       "      <td>Fall</td>\n",
       "      <td>MHxPC130317399</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Master's</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-07-24</td>\n",
       "      <td>2012-08-25</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>197757</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  institute course_id  year semester          userid  viewed  explored  \\\n",
       "0  HarvardX    PH207x  2012     Fall  MHxPC130313697       0         0   \n",
       "1  HarvardX    PH207x  2012     Fall  MHxPC130237753       1         0   \n",
       "2  HarvardX     CS50x  2012   Summer  MHxPC130202970       1         0   \n",
       "3  HarvardX     CS50x  2012   Summer  MHxPC130223941       1         0   \n",
       "4  HarvardX    PH207x  2012     Fall  MHxPC130317399       0         0   \n",
       "\n",
       "   certified                         country   education  grade start_time  \\\n",
       "0          0                           India  Bachelor's    0.0 2012-07-24   \n",
       "1          0                   United States   Secondary    0.0 2012-07-24   \n",
       "2          0                   United States  Bachelor's    0.0 2012-07-24   \n",
       "3          0  Other Middle East/Central Asia   Secondary    0.0 2012-07-24   \n",
       "4          0                       Australia    Master's    0.0 2012-07-24   \n",
       "\n",
       "  last_event  nevents  ndays_act  nplay_video  nchapters  nforum_posts  age  \\\n",
       "0 2013-07-27        6          3       197757          0             0   23   \n",
       "1 2012-12-24      107          8            7          2             0   19   \n",
       "2 2013-03-28        8          1       197757          1             0   24   \n",
       "3 2013-07-15       25          2       197757          4             0   20   \n",
       "4 2012-08-25        3          2       197757          0             0   32   \n",
       "\n",
       "  duration  \n",
       "0 368 days  \n",
       "1 153 days  \n",
       "2 247 days  \n",
       "3 356 days  \n",
       "4  32 days  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mooc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8f8a40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns not usefull for the model\n",
    "\n",
    "mooc = mooc.drop(columns=['course_id','userid','start_time','last_event','year','institute'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "605c5b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical columns \n",
    "\n",
    "categorical = ['semester', 'country', 'education']\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ord_enc = OrdinalEncoder()\n",
    "\n",
    "for i in categorical:\n",
    "    mooc[i] = ord_enc.fit_transform(mooc[[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "883b53ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>semester</th>\n",
       "      <th>viewed</th>\n",
       "      <th>explored</th>\n",
       "      <th>certified</th>\n",
       "      <th>country</th>\n",
       "      <th>education</th>\n",
       "      <th>grade</th>\n",
       "      <th>nevents</th>\n",
       "      <th>ndays_act</th>\n",
       "      <th>nplay_video</th>\n",
       "      <th>nchapters</th>\n",
       "      <th>nforum_posts</th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>197757</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>197757</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>197757</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>197757</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416916</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>197757</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416917</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416918</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>197757</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416919</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>197757</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416920</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>415410 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        semester  viewed  explored  certified  country  education  grade  \\\n",
       "0            0.0       0         0          0     10.0        0.0    0.0   \n",
       "1            0.0       1         0          0     32.0        4.0    0.0   \n",
       "2            2.0       1         0          0     32.0        0.0    0.0   \n",
       "3            2.0       1         0          0     19.0        4.0    0.0   \n",
       "4            0.0       0         0          0      0.0        3.0    0.0   \n",
       "...          ...     ...       ...        ...      ...        ...    ...   \n",
       "416916       1.0       1         0          0     24.0        3.0    0.0   \n",
       "416917       1.0       1         0          0      3.0        0.0    0.0   \n",
       "416918       1.0       0         0          0     18.0        0.0    0.0   \n",
       "416919       1.0       0         0          0     32.0        1.0    0.0   \n",
       "416920       1.0       1         0          0     32.0        1.0    0.0   \n",
       "\n",
       "        nevents  ndays_act  nplay_video  nchapters  nforum_posts  age  \\\n",
       "0             6          3       197757          0             0   23   \n",
       "1           107          8            7          2             0   19   \n",
       "2             8          1       197757          1             0   24   \n",
       "3            25          2       197757          4             0   20   \n",
       "4             3          2       197757          0             0   32   \n",
       "...         ...        ...          ...        ...           ...  ...   \n",
       "416916       29          1       197757          1             0   24   \n",
       "416917       97          1            4          2             0   22   \n",
       "416918        1          1       197757          0             0   22   \n",
       "416919        1          1       197757          0             0   34   \n",
       "416920       74          1           14          1             0   34   \n",
       "\n",
       "        duration  \n",
       "0            368  \n",
       "1            153  \n",
       "2            247  \n",
       "3            356  \n",
       "4             32  \n",
       "...          ...  \n",
       "416916         0  \n",
       "416917         0  \n",
       "416918         0  \n",
       "416919         0  \n",
       "416920         0  \n",
       "\n",
       "[415410 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mooc['duration'] = mooc['duration'].dt.days\n",
    "mooc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51d27ff",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66abbbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split training set and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = mooc.drop('certified', axis=1)\n",
    "y = mooc['certified']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00c7ede1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nModel :  DecisionTreeClassifier(random_state=0) \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    120220\n",
      "           1       0.98      0.98      0.98      4403\n",
      "\n",
      "    accuracy                           1.00    124623\n",
      "   macro avg       0.99      0.99      0.99    124623\n",
      "weighted avg       1.00      1.00      1.00    124623\n",
      "\n",
      "/nModel :  RandomForestClassifier(random_state=2) \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    120220\n",
      "           1       0.98      0.99      0.99      4403\n",
      "\n",
      "    accuracy                           1.00    124623\n",
      "   macro avg       0.99      0.99      0.99    124623\n",
      "weighted avg       1.00      1.00      1.00    124623\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\B590\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nModel :  LogisticRegression(random_state=4) \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99    120220\n",
      "           1       0.71      0.57      0.63      4403\n",
      "\n",
      "    accuracy                           0.98    124623\n",
      "   macro avg       0.85      0.78      0.81    124623\n",
      "weighted avg       0.97      0.98      0.98    124623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build models\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "rfc = RandomForestClassifier(random_state=2)\n",
    "lr = LogisticRegression(random_state=4)\n",
    "models = [dt,rfc,lr]\n",
    "\n",
    "\n",
    "def fit_predict_evaluate_model(model):\n",
    "    \n",
    "    model.fit(X_train,y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    return (classification_report(y_test, predictions))\n",
    "    \n",
    "\n",
    "for m in models:\n",
    "    print('/nModel : ',m,'\\n',fit_predict_evaluate_model(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d18c5c7",
   "metadata": {},
   "source": [
    "From the evaluation metrics above, we conclude that Random Forest Classifier has better performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bbab0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix : \n",
      " [[120135     85]\n",
      " [    47   4356]]\n"
     ]
    }
   ],
   "source": [
    "predictions = rfc.predict(X_test)\n",
    "print ('confusion matrix : \\n',confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44afdc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc_auc_score is  0.9999685242813039\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC curve for the Random Forest Classifier\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "y_score = rfc.predict_proba(X_test)[:,1]\n",
    "labels = list(y_test)\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(labels, y_score)\n",
    "\n",
    "print ('The roc_auc_score is ',roc_auc_score(labels, y_score))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.subplots(1, figsize=(5,5))\n",
    "plt.plot(false_positive_rate, true_positive_rate,color='g')\n",
    "plt.plot([0, 1], ls=\"--\",color='r')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e26821",
   "metadata": {},
   "source": [
    "Let's cut the huge dataset to the size of the dataset with the demographic data of the students. Now we can compare the best performances of the selected models and make conclusions on which type of data are better for predicting students dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58e76730",
   "metadata": {},
   "outputs": [],
   "source": [
    "graduate  = mooc[mooc[\"certified\"]==1][:2209]\n",
    "dropout = graduates = mooc[mooc[\"certified\"]==0][:1421]\n",
    "small_mooc = pd.concat([graduate,dropout],axis=0)        # new data with the same proportions as demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20ac51cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>semester</th>\n",
       "      <th>viewed</th>\n",
       "      <th>explored</th>\n",
       "      <th>certified</th>\n",
       "      <th>country</th>\n",
       "      <th>education</th>\n",
       "      <th>grade</th>\n",
       "      <th>nevents</th>\n",
       "      <th>ndays_act</th>\n",
       "      <th>nplay_video</th>\n",
       "      <th>nchapters</th>\n",
       "      <th>nforum_posts</th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>691</td>\n",
       "      <td>59</td>\n",
       "      <td>197757</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>219</td>\n",
       "      <td>59</td>\n",
       "      <td>197757</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92</td>\n",
       "      <td>29</td>\n",
       "      <td>197757</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>15</td>\n",
       "      <td>197757</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>295</td>\n",
       "      <td>44</td>\n",
       "      <td>197757</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017</td>\n",
       "      <td>9</td>\n",
       "      <td>272</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171</td>\n",
       "      <td>6</td>\n",
       "      <td>197757</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>197757</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3630 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      semester  viewed  explored  certified  country  education  grade  \\\n",
       "25         2.0       1         1          1     18.0        3.0    1.0   \n",
       "123        0.0       1         1          1      6.0        4.0    1.0   \n",
       "175        2.0       1         1          1     12.0        0.0    1.0   \n",
       "206        0.0       1         1          1     10.0        0.0    1.0   \n",
       "215        2.0       1         1          1     24.0        0.0    1.0   \n",
       "...        ...     ...       ...        ...      ...        ...    ...   \n",
       "1500       1.0       1         0          0     18.0        4.0    0.0   \n",
       "1501       1.0       1         0          0      2.0        0.0    0.0   \n",
       "1502       0.0       1         0          0     10.0        3.0    0.0   \n",
       "1503       0.0       1         1          0     10.0        4.0    0.0   \n",
       "1504       0.0       0         0          0      6.0        3.0    0.0   \n",
       "\n",
       "      nevents  ndays_act  nplay_video  nchapters  nforum_posts  age  duration  \n",
       "25        691         59       197757         12             0   29       286  \n",
       "123       219         59       197757         12             0   17       247  \n",
       "175        92         29       197757          9             0   25       274  \n",
       "206        28         15       197757         12             0   21       215  \n",
       "215       295         44       197757         12             0   21       289  \n",
       "...       ...        ...          ...        ...           ...  ...       ...  \n",
       "1500      136          2            2          2             0   33         0  \n",
       "1501        6          2            1          1             0   25       149  \n",
       "1502     1017          9          272          3             6   29       102  \n",
       "1503      171          6       197757         12             0   27       178  \n",
       "1504        1          1       197757          0             0   29         1  \n",
       "\n",
       "[3630 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_mooc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db0addad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = small_mooc.drop('certified', axis=1)\n",
    "y = small_mooc['certified']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31039ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nModel :  DecisionTreeClassifier(random_state=0) \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       440\n",
      "           1       1.00      1.00      1.00       649\n",
      "\n",
      "    accuracy                           1.00      1089\n",
      "   macro avg       1.00      1.00      1.00      1089\n",
      "weighted avg       1.00      1.00      1.00      1089\n",
      "\n",
      "/nModel :  RandomForestClassifier(random_state=2) \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       440\n",
      "           1       1.00      1.00      1.00       649\n",
      "\n",
      "    accuracy                           1.00      1089\n",
      "   macro avg       1.00      1.00      1.00      1089\n",
      "weighted avg       1.00      1.00      1.00      1089\n",
      "\n",
      "/nModel :  LogisticRegression(random_state=4) \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       440\n",
      "           1       0.94      0.95      0.94       649\n",
      "\n",
      "    accuracy                           0.93      1089\n",
      "   macro avg       0.93      0.93      0.93      1089\n",
      "weighted avg       0.93      0.93      0.93      1089\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\B590\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "for m in models:\n",
    "    print('/nModel : ',m,'\\n',fit_predict_evaluate_model(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "769c55ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix : \n",
      " [[439   1]\n",
      " [  0 649]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier has better performance here too.\n",
    "\n",
    "predictions = rfc.predict(X_test)\n",
    "print ('confusion matrix : \\n',confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4853068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
